# Copyright (c) 2025 FloodWatch Team
# SPDX-License-Identifier: MIT
# ======================================================
# FloodWatch Backend - OPTIMIZED VERSION v3.0
# Fixed based on BACKEND_ISSUES_ANALYSIS.md
# ======================================================

import os
import io
import uuid
import logging
import json
from datetime import datetime, timezone
from typing import List, Optional, Dict, Any, Tuple
from contextlib import contextmanager

import asyncio
import requests
from crate import client
from fastapi import FastAPI, UploadFile, Form, File, HTTPException, Request, status, WebSocket, WebSocketDisconnect, Query
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from dotenv import load_dotenv
from cachetools import TTLCache
from PIL import Image
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type

from .services.storage import save_files_local, validate_and_save_files
from .services.orion_client import create_crowd_report_entity
from .schemas import CreateReportResult

# ======================================================
# INIT + CONFIG
# ======================================================

load_dotenv()

# Configure logging with proper encoding
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler("flood_processor.log", encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

app = FastAPI(
    title="üåä FloodWatch API",
    version="3.2.0",
    description="""
## üåä FloodWatch - H·ªá th·ªëng Gi√°m s√°t Ng·∫≠p l·ª•t TP.HCM

**·ª®ng d·ª•ng Smart City** s·ª≠ d·ª•ng c√¥ng ngh·ªá **FIWARE/NGSI-LD** ƒë·ªÉ gi√°m s√°t v√† c·∫£nh b√°o ng·∫≠p l·ª•t th·ªùi gian th·ª±c.

### üéØ T√≠nh nƒÉng ch√≠nh:
- **Real-time flood monitoring** v·ªõi WebSocket
- **15 polygon zones** ng·∫≠p th·ª±c t·∫ø TP.HCM
- **AI-powered chatbot** (Google Gemini)
- **OpenWeather integration** cho d·ª± b√°o th·ªùi ti·∫øt
- **Citizen reports** - B√°o c√°o ng·∫≠p t·ª´ c·ªông ƒë·ªìng

### üèóÔ∏è C√¥ng ngh·ªá:
- **FIWARE Orion-LD** - NGSI-LD Context Broker (chu·∫©n Smart City ch√¢u √Çu)
- **CrateDB** - Time-series + Geo-spatial database
- **QuantumLeap** - Time-series API cho NGSI-LD
- **Docker** - Container orchestration

### üìä Severity Levels:
| Level | Water Level | M√¥ t·∫£ |
|-------|-------------|-------|
| üü¢ Low | < 0.2m | D∆∞·ªõi 20cm - kh√¥ng ƒë√°ng lo |
| üü° Moderate | 0.2-0.5m | 20-50cm - c·∫ßn ch√∫ √Ω |
| üü† High | 0.5-1.0m | 50-100cm - nguy hi·ªÉm |
| üî¥ Severe | > 1.0m | Tr√™n 100cm - r·∫•t nguy hi·ªÉm |

### üîó Links:
- [GitHub Repository](https://github.com/FloodWatch)
- [FIWARE Documentation](https://fiware.org)

---
*Developed for OLP 2025 Competition*
    """,
    docs_url="/docs",
    redoc_url="/redoc",
    openapi_tags=[
        {
            "name": "Dashboard",
            "description": "üìä **Th·ªëng k√™ t·ªïng quan** - API cho dashboard v√† th·ªëng k√™ theo qu·∫≠n/huy·ªán"
        },
        {
            "name": "Flood Data",
            "description": "üåä **D·ªØ li·ªáu ng·∫≠p l·ª•t** - API l·∫•y d·ªØ li·ªáu ng·∫≠p t·ª´ sensors v√† crowd reports"
        },
        {
            "name": "Reports",
            "description": "üìù **B√°o c√°o ng∆∞·ªùi d√¢n** - API cho citizen reports v·ªÅ t√¨nh tr·∫°ng ng·∫≠p"
        },
        {
            "name": "Weather",
            "description": "üå§Ô∏è **D·ª± b√°o th·ªùi ti·∫øt** - API t√≠ch h·ª£p OpenWeather cho 22 qu·∫≠n TP.HCM"
        },
        {
            "name": "Chatbot",
            "description": "ü§ñ **AI Assistant** - Chatbot t√≠ch h·ª£p Google Gemini AI"
        },
        {
            "name": "WebSocket",
            "description": "‚ö° **Real-time** - WebSocket cho c·∫≠p nh·∫≠t d·ªØ li·ªáu th·ªùi gian th·ª±c"
        },
        {
            "name": "Health",
            "description": "üíö **System Health** - Ki·ªÉm tra tr·∫°ng th√°i h·ªá th·ªëng"
        },
        {
            "name": "Prediction",
            "description": "üîÆ **D·ª± ƒëo√°n ng·∫≠p** - AI-powered flood prediction"
        },
        {
            "name": "Alerts",
            "description": "‚ö†Ô∏è **C·∫£nh b√°o h·ªá th·ªëng** - API t·∫°o m√¥ t·∫£ c·∫£nh b√°o th√¥ng minh b·∫±ng Gemini AI"
        }
    ],
    contact={
        "name": "FloodWatch Team",
        "email": "floodwatch@olp2025.vn"
    },
    license_info={
        "name": "MIT License",
        "url": "https://opensource.org/licenses/MIT"
    }
)

# CORS
CORS_ORIGINS = os.getenv("CORS_ORIGINS", "*").split(",")
app.add_middleware(
    CORSMiddleware,
    allow_origins=CORS_ORIGINS,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Static files
app.mount("/static", StaticFiles(directory="app/static"), name="static")

# Orion-LD config
ORION_LD_URL = os.getenv("ORION_ENTITIES", "http://orion-ld:1026/ngsi-ld/v1/entities")
CONTEXT = "https://uri.etsi.org/ngsi-ld/v1/ngsi-ld-core-context-v1.6.jsonld"
BASE_URL = os.getenv("BASE_URL")

# CrateDB configuration
CRATEDB_HTTP_URL = os.getenv("CRATEDB_HTTP_URL", "http://cratedb:4200")
CRATEDB_USER = os.getenv("CRATEDB_USER", "crate")
CRATEDB_DSN = os.getenv("CRATEDB_DSN", "postgresql://crate@cratedb:5432/quantumleap")

# ======================================================
# CONNECTION POOL - OPTIMIZED
# ======================================================

# Global connection pool (singleton)
_connection_pool = None

def get_connection_pool():
    """Get or create connection pool (lazy initialization)."""
    global _connection_pool
    if _connection_pool is None:
        _connection_pool = client.connect(
            CRATEDB_HTTP_URL, 
            username=CRATEDB_USER
        )
    return _connection_pool

@contextmanager
def get_db_cursor():
    """Context manager for database cursor with connection pooling."""
    conn = get_connection_pool()
    cursor = conn.cursor()
    try:
        yield cursor
    finally:
        cursor.close()

# ======================================================
# TTL CACHE - OPTIMIZED (thay th·∫ø lru_cache)
# ======================================================

# Cache v·ªõi TTL 30 gi√¢y
snapshot_cache = TTLCache(maxsize=10, ttl=30)
sensor_cache = TTLCache(maxsize=10, ttl=30)

def cached_get_snapshot_crowd(limit: int = 1000) -> list:
    """Get crowd snapshot with TTL cache."""
    cache_key = f"crowd_{limit}"
    if cache_key in snapshot_cache:
        return snapshot_cache[cache_key]
    result = get_snapshot_crowd(limit)
    snapshot_cache[cache_key] = result
    return result

def cached_get_snapshot_sensor(limit: int = 1000) -> list:
    """Get sensor snapshot with TTL cache."""
    cache_key = f"sensor_{limit}"
    if cache_key in sensor_cache:
        return sensor_cache[cache_key]
    result = get_snapshot_sensor(limit)
    sensor_cache[cache_key] = result
    return result

# ======================================================
# UTILITIES
# ======================================================

def now_iso() -> str:
    """Get current UTC time in ISO format."""
    return datetime.now(timezone.utc).isoformat()

def validate_location(location: Dict[str, Any]) -> Dict[str, Any]:
    """Validate and normalize location data structure."""
    if not isinstance(location, dict):
        return None
        
    # If it's already a GeoProperty, return as is
    if location.get("type") == "GeoProperty":
        return location
        
    # If it's a direct value, wrap it in GeoProperty
    if "type" in location and "coordinates" in location:
        return {
            "type": "GeoProperty",
            "value": location
        }
    return None

def validate_coordinates(lat: float, lng: float, precision_check: bool = False) -> bool:
    """
    Validate coordinates for Vietnam with improved bounds.
    
    Vietnam bounds (tighter):
    - North: 23.4¬∞N, South: 8.5¬∞N
    - West: 102.1¬∞E, East: 109.5¬∞E
    """
    if lat is None or lng is None:
        return False
    
    # Check for default/invalid values (GPS default)
    if lat == 0.0 and lng == 0.0:
        return False
    
    # Vietnam bounds (tighter)
    if not (8.5 <= lat <= 23.4 and 102.1 <= lng <= 109.5):
        return False
    
    # Optional precision check
    if precision_check:
        lat_decimals = len(str(lat).split('.')[-1]) if '.' in str(lat) else 0
        lng_decimals = len(str(lng).split('.')[-1]) if '.' in str(lng) else 0
        if lat_decimals < 4 or lng_decimals < 4:
            logger.warning(f"Low precision coordinates: {lat}, {lng}")
    
    return True

# ======================================================
# SEVERITY CALCULATION - FIXED (theo BACKEND_ISSUES_ANALYSIS)
# ======================================================

def compute_flood_severity(water_level: float, threshold: float = None, trend: float = None) -> str:
    """
    ‚úÖ FIXED: T√≠nh severity d·ª±a tr√™n m·ª©c n∆∞·ªõc tuy·ªát ƒë·ªëi v√† ng·ªØ c·∫£nh Vi·ªát Nam
    
    - water_level < 0.2m: Low (d∆∞·ªõi 20cm - kh√¥ng ƒë√°ng lo)
    - water_level 0.2-0.5m: Moderate (20-50cm - c·∫ßn ch√∫ √Ω)
    - water_level 0.5-1.0m: High (50-100cm - nguy hi·ªÉm)
    - water_level > 1.0m: Severe (tr√™n 100cm - r·∫•t nguy hi·ªÉm)
    """
    # ‚úÖ Ph√¢n lo·∫°i theo m·ª©c n∆∞·ªõc tuy·ªát ƒë·ªëi (Vi·ªát Nam context)
    if water_level < 0.2:  # < 20cm
        base_severity = "Low"
    elif water_level < 0.5:  # 20-50cm
        base_severity = "Moderate"
    elif water_level < 1.0:  # 50-100cm
        base_severity = "High"
    else:  # > 100cm
        base_severity = "Severe"
    
    # ‚úÖ X√©t threshold (ng∆∞·ª°ng c·∫£nh b√°o ƒë·ªãa ph∆∞∆°ng) n·∫øu c√≥
    if threshold and threshold > 0 and water_level >= threshold:
        if base_severity in ["Low", "Moderate"]:
            base_severity = "High"
    
    # ‚úÖ X√©t xu h∆∞·ªõng tƒÉng (trend) v·ªõi ng∆∞·ª°ng th·∫•p h∆°n
    severity_levels = ["Low", "Moderate", "High", "Severe"]
    current_idx = severity_levels.index(base_severity)
    
    if trend is not None:
        if trend > 0.05:  # TƒÉng > 5cm/h - nguy hi·ªÉm
            if current_idx < len(severity_levels) - 1:
                base_severity = severity_levels[current_idx + 1]
        elif trend > 0.1:  # TƒÉng > 10cm/h - r·∫•t nguy hi·ªÉm
            if current_idx < len(severity_levels) - 2:
                base_severity = severity_levels[min(current_idx + 2, 3)]
    
    return base_severity

def severity_from_level(level: float, threshold: float) -> str:
    """Wrapper for backward compatibility."""
    return compute_flood_severity(level, threshold)

# ======================================================
# RISK SCORE CALCULATION - FIXED (theo BACKEND_ISSUES_ANALYSIS)
# ======================================================

def calculate_crowd_risk_score(
    water_level: float,
    description: str = "",
    photos: list = None,
    verified: bool = False
) -> Tuple[float, str, dict]:
    """
    ‚úÖ FIXED: T√≠nh risk score v·ªõi logic c·∫£i ti·∫øn
    
    Returns: (risk_score, risk_level, factors)
    """
    photos = photos or []
    
    # ‚úÖ 1. Water level score - phi tuy·∫øn t√≠nh (quan tr·ªçng nh·∫•t)
    if water_level < 0.3:
        water_level_score = water_level / 0.3 * 0.3  # 0-0.3
    elif water_level < 0.8:
        water_level_score = 0.3 + (water_level - 0.3) / 0.5 * 0.4  # 0.3-0.7
    else:
        water_level_score = 0.7 + min((water_level - 0.8) / 1.2 * 0.3, 0.3)  # 0.7-1.0
    
    # ‚úÖ 2. Photo evidence score (nhi·ªÅu ·∫£nh = ƒë·ªô tin c·∫≠y cao)
    photo_score = min(len(photos) * 0.25, 1.0) if photos else 0.0
    
    # ‚úÖ 3. Text severity score v·ªõi keywords ti·∫øng Vi·ªát
    severity_keywords_vi = [
        "nguy hi·ªÉm", "nghi√™m tr·ªçng", "ng·∫≠p s√¢u", "k·∫πt xe", "kh√¥ng qua ƒë∆∞·ª£c",
        "n∆∞·ªõc ch·∫£y m·∫°nh", "ng·∫≠p n·∫∑ng", "tr√†n b·ªù", "s·ª•p ƒë·ªï", "c·ª©u", "gi√∫p",
        "ch·∫øt ng∆∞·ªùi", "cu·ªën tr√¥i", "m·∫Øc k·∫πt", "ng·∫≠p ƒë·∫øn", "ngang ng∆∞·ªùi",
        "ng·∫≠p l·ª•t", "kh·∫©n c·∫•p", "nguy c·∫•p"
    ]
    severity_keywords_en = [
        "danger", "severe", "overflow", "stuck", "blocked", "deep",
        "emergency", "flood", "help", "rescue", "dangerous"
    ]
    all_keywords = severity_keywords_vi + severity_keywords_en
    
    description_lower = description.lower() if description else ""
    keyword_matches = sum(1 for w in all_keywords if w in description_lower)
    
    if keyword_matches >= 3:
        text_severity_score = 1.0
    elif keyword_matches >= 1:
        text_severity_score = 0.7
    elif len(description) > 50:
        text_severity_score = 0.4
    elif len(description) > 20:
        text_severity_score = 0.3
    else:
        text_severity_score = 0.1
    
    # ‚úÖ 4. Verified boost (ch·ªâ tƒÉng confidence, kh√¥ng ·∫£nh h∆∞·ªüng qu√° nhi·ªÅu)
    verified_boost = 0.15 if verified else 0.0
    
    # ‚úÖ 5. Final risk score v·ªõi tr·ªçng s·ªë h·ª£p l√Ω
    risk_score = round(
        0.50 * water_level_score +      # 50% t·ª´ m·ª©c n∆∞·ªõc (quan tr·ªçng nh·∫•t)
        0.25 * text_severity_score +    # 25% t·ª´ m√¥ t·∫£
        0.15 * photo_score +            # 15% t·ª´ ·∫£nh
        0.10 * (1.0 if verified else 0.5),  # 10% t·ª´ verified status
        3
    )
    
    # Clamp to [0, 1]
    risk_score = max(0.0, min(1.0, risk_score))
    
    # ‚úÖ 6. Determine risk level
    if risk_score > 0.75:
        risk_level = "Severe"
    elif risk_score > 0.55:
        risk_level = "High"
    elif risk_score > 0.35:
        risk_level = "Moderate"
    else:
        risk_level = "Low"
    
    factors = {
        "waterLevelFactor": round(water_level_score, 3),
        "textSeverityFactor": round(text_severity_score, 3),
        "photoFactor": round(photo_score, 3),
        "verifiedFactor": round(verified_boost, 3),
        "keywordMatches": keyword_matches
    }
    
    return risk_score, risk_level, factors

# ======================================================
# DATABASE QUERIES - OPTIMIZED with Connection Pool
# ======================================================

def execute_query(query: str, params: list = None) -> list:
    """Execute CrateDB query with connection pooling."""
    try:
        with get_db_cursor() as cursor:
            cursor.execute(query, params or [])
            columns = [desc[0] for desc in cursor.description]
            return [dict(zip(columns, row)) for row in cursor.fetchall()]
    except Exception as e:
        logger.error(f"CrateDB Query ERROR: {str(e)}")
        # Reset connection pool on error
        global _connection_pool
        _connection_pool = None
        return []

def deduplicate_by_coordinates(records: List[Dict], coord_precision: int = 5) -> List[Dict]:
    """
    Remove duplicate records with same coordinates.
    coord_precision: number of decimal places (5 = ~1.1m accuracy)
    """
    seen = set()
    unique_records = []
    
    for record in records:
        lat = record.get('lat')
        lng = record.get('lng')
        
        if not validate_coordinates(lat, lng):
            continue
        
        coord_key = (round(lat, coord_precision), round(lng, coord_precision))
        
        if coord_key not in seen:
            seen.add(coord_key)
            unique_records.append(record)
    
    return unique_records

# ===========================================================
# SNAPSHOT QUERIES - OPTIMIZED v·ªõi x√≥a c≈© l·∫•y m·ªõi
# ===========================================================

def get_snapshot_crowd(limit: int = 1000) -> list:
    """Get latest crowd reports - ch·ªâ l·∫•y record m·ªõi nh·∫•t cho m·ªói v·ªã tr√≠."""
    records = execute_query(f"""
        SELECT 
            entity_id,
            entity_type,
            longitude(location_centroid) AS lng,
            latitude(location_centroid) AS lat,
            riskscore,
            risklevel,
            waterlevel,
            address,
            calculatedat
        FROM doc.etfloodriskcrowd
        WHERE location_centroid IS NOT NULL
        AND calculatedat > NOW() - INTERVAL '24 hours'
        ORDER BY calculatedat DESC
        LIMIT {limit}
    """)
    
    # Deduplicate - ch·ªâ gi·ªØ record m·ªõi nh·∫•t cho m·ªói t·ªça ƒë·ªô
    unique_records = deduplicate_by_coordinates(records)
    logger.info(f"Crowd: {len(records)} raw ‚Üí {len(unique_records)} unique (24h)")
    
    return unique_records

def get_snapshot_sensor(limit: int = 1000) -> list:
    """
    ‚úÖ OPTIMIZED: Get latest sensor data from WaterLevelObserved entities
    Simulator creates WaterLevelObserved entities with zoneId for polygon zones.
    L·∫•y record m·ªõi nh·∫•t cho m·ªói zone.
    """
    # ‚úÖ FIX: S·ª≠ d·ª•ng subquery ƒë·ªÉ l·∫•y record m·ªõi nh·∫•t c·ªßa m·ªói zoneid
    # Tr√°nh v·∫•n ƒë·ªÅ LIMIT ch·ªâ l·∫•y m·ªôt s·ªë zones ƒë·∫ßu alphabet
    records = execute_query(f"""
        SELECT 
            t.entity_id,
            t.entity_type,
            t.zoneid AS sensorinstanceid,
            longitude(t.location_centroid) AS lng,
            latitude(t.location_centroid) AS lat,
            t.waterlevel,
            t.district,
            t.watertrend,
            t.zoneid,
            t.zonename,
            t.reporttype,
            t.time_index
        FROM doc.etwaterlevelobserved t
        INNER JOIN (
            SELECT zoneid, MAX(time_index) as max_time
            FROM doc.etwaterlevelobserved
            WHERE location_centroid IS NOT NULL
            GROUP BY zoneid
        ) latest ON t.zoneid = latest.zoneid AND t.time_index = latest.max_time
        WHERE t.location_centroid IS NOT NULL
        AND latitude(t.location_centroid) BETWEEN 8.5 AND 23.4
        AND longitude(t.location_centroid) BETWEEN 102.1 AND 109.5
        ORDER BY t.zoneid
        LIMIT {limit}
    """)
    
    # Fallback: Try FloodRiskSensor table if WaterLevelObserved is empty
    if not records:
        logger.info("WaterLevelObserved empty, falling back to FloodRiskSensor")
        records = execute_query(f"""
            SELECT 
                t.entity_id,
                t.entity_type,
                t.sensorinstanceid,
                longitude(t.location_centroid) AS lng,
                latitude(t.location_centroid) AS lat,
                t.severity,
                t.waterlevel,
                t.district,
                t.updatedat,
                t.zoneid,
                t.zonename,
                t.watertrend
            FROM doc.etfloodrisksensor t
            WHERE t.location_centroid IS NOT NULL
            AND latitude(t.location_centroid) BETWEEN 8.5 AND 23.4
            AND longitude(t.location_centroid) BETWEEN 102.1 AND 109.5
            ORDER BY t.updatedat DESC
            LIMIT {limit}
        """)
    
    # Deduplicate by zoneId (for polygon zones) or coordinates
    seen_zones = set()
    seen_coords = set()
    unique_records = []
    
    for record in records:
        lat = record.get('lat')
        lng = record.get('lng')
        zone_id = record.get('zoneid')
        
        if not validate_coordinates(lat, lng):
            continue
        
        # Skip n·∫øu ƒë√£ th·∫•y zone n√†y
        if zone_id:
            if zone_id in seen_zones:
                continue
            seen_zones.add(zone_id)
        else:
            # Fallback to coordinate-based dedup
            coord_key = (round(lat, 4), round(lng, 4))
            if coord_key in seen_coords:
                continue
            seen_coords.add(coord_key)
        
        # ‚úÖ Calculate severity from water level for WaterLevelObserved
        water_level = record.get('waterlevel', 0)
        if not record.get('severity'):
            record['severity'] = compute_flood_severity(water_level)
        
        # ‚úÖ Map updatedat from entity_id timestamp or use current time
        if not record.get('updatedat'):
            record['updatedat'] = now_iso()
        
        unique_records.append(record)
    
    logger.info(f"Sensor: {len(records)} raw ‚Üí {len(unique_records)} unique zones")
    
    return unique_records

# ===========================================================
# RADIUS FILTER - NEW FEATURE
# ===========================================================

def filter_by_radius(
    records: List[Dict], 
    center_lat: float, 
    center_lng: float, 
    radius_km: float
) -> List[Dict]:
    """
    ‚úÖ NEW: L·ªçc records theo b√°n k√≠nh t·ª´ ƒëi·ªÉm trung t√¢m.
    
    Args:
        records: Danh s√°ch records v·ªõi lat/lng
        center_lat: Vƒ© ƒë·ªô t√¢m
        center_lng: Kinh ƒë·ªô t√¢m
        radius_km: B√°n k√≠nh t√≠nh b·∫±ng km
    
    Returns:
        Danh s√°ch records trong b√°n k√≠nh
    """
    from math import radians, cos, sin, asin, sqrt
    
    def haversine(lat1: float, lng1: float, lat2: float, lng2: float) -> float:
        """Calculate distance between two points in km."""
        R = 6371  # Earth radius in km
        
        lat1, lng1, lat2, lng2 = map(radians, [lat1, lng1, lat2, lng2])
        dlat = lat2 - lat1
        dlng = lng2 - lng1
        
        a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlng/2)**2
        c = 2 * asin(sqrt(a))
        
        return R * c
    
    filtered = []
    for record in records:
        lat = record.get('lat')
        lng = record.get('lng')
        
        if lat is None or lng is None:
            continue
        
        distance = haversine(center_lat, center_lng, lat, lng)
        if distance <= radius_km:
            record['distance_km'] = round(distance, 2)
            filtered.append(record)
    
    # Sort by distance
    filtered.sort(key=lambda x: x.get('distance_km', 0))
    
    return filtered

# ===========================================================
# INCREMENTAL QUERIES - OPTIMIZED
# ===========================================================

def get_crowd_after(timestamp) -> list:
    """Get new crowd reports after timestamp."""
    records = execute_query("""
        SELECT 
            entity_id,
            entity_type,
            longitude(location_centroid) AS lng,
            latitude(location_centroid) AS lat,
            riskscore,
            risklevel,
            waterlevel,
            address,
            calculatedat
        FROM doc.etfloodriskcrowd
        WHERE calculatedat > ?
        AND location_centroid IS NOT NULL
        ORDER BY calculatedat DESC
        LIMIT 100
    """, [timestamp])
    
    return deduplicate_by_coordinates(records)

def get_sensor_after(timestamp) -> list:
    """Get new sensor data after timestamp.
    ‚úÖ FIX: Query t·ª´ WaterLevelObserved table v·ªõi polygon zone fields
    L·∫•y record m·ªõi nh·∫•t c·ªßa m·ªói zone.
    """
    # Try WaterLevelObserved first (from simulator polygon zones)
    # S·ª≠ d·ª•ng subquery ƒë·ªÉ l·∫•y record m·ªõi nh·∫•t c·ªßa m·ªói zoneid
    records = execute_query("""
        SELECT 
            t.entity_id,
            t.entity_type,
            t.zoneid AS sensorinstanceid,
            longitude(t.location_centroid) AS lng,
            latitude(t.location_centroid) AS lat,
            t.waterlevel,
            t.district,
            t.watertrend,
            t.zoneid,
            t.zonename,
            t.reporttype,
            t.time_index
        FROM doc.etwaterlevelobserved t
        INNER JOIN (
            SELECT zoneid, MAX(time_index) as max_time
            FROM doc.etwaterlevelobserved
            WHERE location_centroid IS NOT NULL
            GROUP BY zoneid
        ) latest ON t.zoneid = latest.zoneid AND t.time_index = latest.max_time
        WHERE t.location_centroid IS NOT NULL
        ORDER BY t.zoneid
        LIMIT 100
    """)
    
    # Add severity and updatedat for each record
    for record in records:
        water_level = record.get('waterlevel', 0)
        record['severity'] = compute_flood_severity(water_level)
        record['updatedat'] = now_iso()
    
    # Fallback to FloodRiskSensor if empty
    if not records:
        records = execute_query("""
            SELECT 
                entity_id,
                entity_type,
                sensorinstanceid,
                longitude(location_centroid) AS lng,
                latitude(location_centroid) AS lat,
                severity,
                waterlevel,
                district,
                updatedat,
                zoneid,
                zonename,
                watertrend
            FROM doc.etfloodrisksensor
            WHERE updatedat > ?
            AND location_centroid IS NOT NULL
            ORDER BY updatedat DESC
            LIMIT 100
        """, [timestamp])
    
    return deduplicate_by_coordinates(records)

# ===========================================================
# DASHBOARD STATISTICS API - ENHANCED
# ===========================================================

@app.get("/api/dashboard/stats", tags=["Dashboard"], summary="Th·ªëng k√™ t·ªïng quan")
async def get_dashboard_stats(
    lat: Optional[float] = Query(None, description="Vƒ© ƒë·ªô t√¢m ƒë·ªÉ l·ªçc theo b√°n k√≠nh"),
    lng: Optional[float] = Query(None, description="Kinh ƒë·ªô t√¢m ƒë·ªÉ l·ªçc theo b√°n k√≠nh"),
    radius: Optional[float] = Query(None, description="B√°n k√≠nh l·ªçc (km)", ge=0.1, le=100)
):
    """
    üìä **L·∫•y th·ªëng k√™ t·ªïng quan cho Dashboard**
    
    Tr·∫£ v·ªÅ:
    - T·ªïng s·ªë ƒëi·ªÉm ng·∫≠p
    - S·ªë l∆∞·ª£ng theo m·ª©c ƒë·ªô (Severe/High/Medium/Low)
    - M·ª©c n∆∞·ªõc trung b√¨nh
    - S·ªë li·ªáu t·ª´ sensors v√† community reports
    
    **H·ªó tr·ª£ l·ªçc theo b√°n k√≠nh**: Cung c·∫•p `lat`, `lng`, `radius` ƒë·ªÉ l·ªçc d·ªØ li·ªáu trong ph·∫°m vi.
    """
    try:
        crowd = cached_get_snapshot_crowd(1000)
        sensor = cached_get_snapshot_sensor(1000)
        
        # ‚úÖ Apply radius filter if provided
        if lat is not None and lng is not None and radius is not None:
            crowd = filter_by_radius(crowd, lat, lng, radius)
            sensor = filter_by_radius(sensor, lat, lng, radius)
            logger.info(f"Filtered by radius {radius}km from ({lat}, {lng})")
        
        total_points = len(crowd) + len(sensor)
        
        # Severity counts
        severe_count = len([r for r in crowd if r.get('risklevel') == 'Severe'])
        severe_count += len([r for r in sensor if r.get('severity') == 'Severe'])
        
        high_count = len([r for r in crowd if r.get('risklevel') == 'High'])
        high_count += len([r for r in sensor if r.get('severity') == 'High'])
        
        medium_count = len([r for r in crowd if r.get('risklevel') in ['Moderate', 'Medium']])
        medium_count += len([r for r in sensor if r.get('severity') in ['Moderate', 'Medium']])
        
        low_count = total_points - severe_count - high_count - medium_count
        
        # Average water level
        all_water_levels = []
        all_water_levels.extend([r.get('waterlevel', 0) for r in crowd if r.get('waterlevel')])
        all_water_levels.extend([r.get('waterlevel', 0) for r in sensor if r.get('waterlevel')])
        avg_water_level = sum(all_water_levels) / len(all_water_levels) if all_water_levels else 0
        
        return {
            "total": total_points,
            "severe": severe_count,
            "high": high_count,
            "medium": medium_count,
            "low": low_count,
            "avgWaterLevel": round(avg_water_level, 2),
            "sensorCount": len(sensor),
            "communityCount": len(crowd),
            "lastUpdated": now_iso(),
            "filter": {
                "lat": lat,
                "lng": lng,
                "radius_km": radius
            } if radius else None
        }
    except Exception as e:
        logger.error(f"Dashboard stats error: {str(e)}")
        raise HTTPException(500, "Failed to get dashboard stats")

@app.get("/api/dashboard/districts", tags=["Dashboard"], summary="Th·ªëng k√™ theo qu·∫≠n/huy·ªán")
async def get_district_summary():
    """
    üìä **T·ªïng h·ª£p t√¨nh tr·∫°ng ng·∫≠p theo qu·∫≠n/huy·ªán**
    
    Tr·∫£ v·ªÅ danh s√°ch c√°c qu·∫≠n v·ªõi:
    - S·ªë ƒëi·ªÉm ng·∫≠p
    - S·ªë ƒëi·ªÉm Severe/High
    - M·ª©c n∆∞·ªõc trung b√¨nh
    
    S·∫Øp x·∫øp theo m·ª©c ƒë·ªô nghi√™m tr·ªçng (qu·∫≠n ng·∫≠p n·∫∑ng nh·∫•t tr∆∞·ªõc).
    """
    try:
        sensor_data = cached_get_snapshot_sensor(1000)
        
        districts = {}
        for record in sensor_data:
            district = record.get('district', 'Unknown')
            if district not in districts:
                districts[district] = {
                    'district': district,
                    'total': 0,
                    'severe': 0,
                    'high': 0,
                    'avgWaterLevel': 0,
                    'waterLevels': []
                }
            
            districts[district]['total'] += 1
            severity = record.get('severity', 'Low')
            if severity == 'Severe':
                districts[district]['severe'] += 1
            elif severity == 'High':
                districts[district]['high'] += 1
            
            water_level = record.get('waterlevel', 0)
            if water_level:
                districts[district]['waterLevels'].append(water_level)
        
        result = []
        for district_name, data in districts.items():
            if data['waterLevels']:
                data['avgWaterLevel'] = round(sum(data['waterLevels']) / len(data['waterLevels']), 2)
            del data['waterLevels']
            result.append(data)
        
        result.sort(key=lambda x: (x['severe'], x['high'], x['total']), reverse=True)
        
        return {"districts": result, "timestamp": now_iso()}
    except Exception as e:
        logger.error(f"District summary error: {str(e)}")
        raise HTTPException(500, "Failed to get district summary")

# ===========================================================
# FLOOD DATA API WITH RADIUS - NEW
# ===========================================================

@app.get("/api/flood/nearby", tags=["Flood Data"], summary="ƒêi·ªÉm ng·∫≠p g·∫ßn v·ªã tr√≠")
async def get_nearby_floods(
    lat: float = Query(..., description="Vƒ© ƒë·ªô trung t√¢m", example=10.762622),
    lng: float = Query(..., description="Kinh ƒë·ªô trung t√¢m", example=106.660172),
    radius: float = Query(5.0, description="B√°n k√≠nh t√¨m ki·∫øm (km)", ge=0.1, le=100),
    limit: int = Query(100, description="S·ªë k·∫øt qu·∫£ t·ªëi ƒëa", ge=1, le=500)
):
    """
    üåä **T√¨m ƒëi·ªÉm ng·∫≠p trong b√°n k√≠nh**
    
    L·∫•y t·∫•t c·∫£ d·ªØ li·ªáu ng·∫≠p (sensors + citizen reports) trong ph·∫°m vi b√°n k√≠nh t·ª´ m·ªôt ƒëi·ªÉm.
    
    **V√≠ d·ª•**: T√¨m ƒëi·ªÉm ng·∫≠p trong 5km quanh Qu·∫≠n 1
    ```
    GET /api/flood/nearby?lat=10.762622&lng=106.660172&radius=5
    ```
    
    Tr·∫£ v·ªÅ:
    - Danh s√°ch crowd reports g·∫ßn ƒë√≥
    - Danh s√°ch sensor data g·∫ßn ƒë√≥
    - Kho·∫£ng c√°ch t·ª´ m·ªói ƒëi·ªÉm ƒë·∫øn t√¢m (km)
    """
    try:
        if not validate_coordinates(lat, lng):
            raise HTTPException(400, "Invalid coordinates for Vietnam")
        
        crowd = cached_get_snapshot_crowd(1000)
        sensor = cached_get_snapshot_sensor(1000)
        
        # Filter by radius
        nearby_crowd = filter_by_radius(crowd, lat, lng, radius)[:limit]
        nearby_sensor = filter_by_radius(sensor, lat, lng, radius)[:limit]
        
        return {
            "center": {"lat": lat, "lng": lng},
            "radius_km": radius,
            "crowd_reports": nearby_crowd,
            "sensor_data": nearby_sensor,
            "total_crowd": len(nearby_crowd),
            "total_sensor": len(nearby_sensor),
            "timestamp": now_iso()
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Nearby floods error: {str(e)}")
        raise HTTPException(500, "Failed to get nearby floods")

# ===========================================================
# WEBSOCKET HANDLER - OPTIMIZED
# ===========================================================

@app.websocket("/ws/map")
async def websocket_map(ws: WebSocket):
    """Optimized WebSocket for real-time map updates."""
    await ws.accept()
    
    last_crowd_ts = None
    last_sensor_ts = None
    
    try:
        while True:
            msg = await ws.receive_text()
            data = json.loads(msg)
            msg_type = data.get("type")
            
            # STEP 1 ‚Äî INITIAL SNAPSHOT
            if msg_type == "init":
                logger.info("WebSocket: Sending initial snapshot")
                
                # Get radius filter from client if provided
                radius = data.get("radius")
                center_lat = data.get("lat")
                center_lng = data.get("lng")
                
                crowd = cached_get_snapshot_crowd()
                sensor = cached_get_snapshot_sensor()
                
                # Apply radius filter if provided
                if radius and center_lat and center_lng:
                    crowd = filter_by_radius(crowd, center_lat, center_lng, radius)
                    sensor = filter_by_radius(sensor, center_lat, center_lng, radius)
                    logger.info(f"WebSocket: Applied radius filter {radius}km")
                
                # Track timestamps
                if crowd:
                    last_crowd_ts = crowd[0].get("calculatedat")
                if sensor:
                    last_sensor_ts = sensor[0].get("updatedat")
                
                await ws.send_text(json.dumps({
                    "type": "snapshot",
                    "crowd": crowd,
                    "sensor": sensor,
                    "timestamp": now_iso()
                }, default=str))
                
                logger.info(f"Snapshot sent: {len(crowd)} crowd + {len(sensor)} sensor")
                continue
            
            # STEP 2 ‚Äî POLLING FOR UPDATES
            if msg_type == "poll":
                updates = {"type": "update", "crowd": [], "sensor": [], "timestamp": now_iso()}
                
                if last_crowd_ts:
                    new_crowd = get_crowd_after(last_crowd_ts)
                    if new_crowd:
                        last_crowd_ts = new_crowd[0].get("calculatedat")
                        updates["crowd"] = new_crowd
                
                if last_sensor_ts:
                    new_sensor = get_sensor_after(last_sensor_ts)
                    if new_sensor:
                        last_sensor_ts = new_sensor[0].get("updatedat")
                        updates["sensor"] = new_sensor
                
                if updates["crowd"] or updates["sensor"]:
                    await ws.send_text(json.dumps(updates, default=str))
    
    except WebSocketDisconnect:
        logger.info("WebSocket disconnected normally")
    except Exception as e:
        logger.error(f"WebSocket error: {str(e)}", exc_info=True)
    finally:
        try:
            await ws.close()
        except:
            pass

# ======================================================
# RETRY MECHANISM for Orion-LD
# ======================================================

@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=2, max=10),
    retry=retry_if_exception_type(requests.exceptions.RequestException)
)
def send_to_orion(entity: dict) -> requests.Response:
    """Send entity to Orion-LD with retry mechanism."""
    headers = {"Content-Type": "application/ld+json"}
    response = requests.post(ORION_LD_URL, json=entity, headers=headers, timeout=10)
    response.raise_for_status()
    return response

# ======================================================
# SENSOR ROUTE ‚Üí FloodRiskSensor - FIXED
# ======================================================

@app.post("/flood/sensor")
async def process_flood_sensor(request: Request):
    """Process flood sensor data from IoT devices.
    ‚úÖ NEW: H·ªó tr·ª£ polygon zones v·ªõi zoneId, zoneName
    """
    try:
        raw = await request.json()
        logger.info("Received sensor data")

        if "data" not in raw or len(raw["data"]) == 0:
            raise HTTPException(400, "Invalid NGSI-LD notification format: missing data[]")

        data = raw["data"][0]
        
        district = data.get("district", {}).get("value")
        water_level = data.get("waterLevel", {}).get("value")
        threshold = data.get("alertThreshold", {}).get("value")
        location = validate_location(data.get("location", {}))
        source_id = data.get("id")
        
        # ‚úÖ NEW: Extract polygon zone fields
        zone_id = data.get("zoneId", {}).get("value")
        zone_name = data.get("zoneName", {}).get("value")

        if not all([water_level is not None, location, source_id]):
            raise HTTPException(400, "Missing required fields: waterLevel, location, or id")

        # ‚úÖ FIXED: D√πng h√†m compute_flood_severity m·ªõi
        trend = data.get("waterTrend", {}).get("value")
        severity = compute_flood_severity(water_level, threshold, trend)

        entity = {
            "id": f"urn:ngsi-ld:FloodRiskSensor:{uuid.uuid4()}",
            "type": "FloodRiskSensor",
            "location": location,
            "severity": {"type": "Property", "value": severity},
            "waterLevel": {
                "type": "Property",
                "value": water_level,
                "unitCode": "MTR",
                "observedAt": data.get("waterLevel", {}).get("observedAt", now_iso()),
            },
            "alertThreshold": {"type": "Property", "value": threshold or 1.0, "unitCode": "MTR"},
            "confidence": {"type": "Property", "value": "High"},
            "sourceSensor": {"type": "Relationship", "object": source_id},
            "updatedAt": {"type": "Property", "value": now_iso()},
            "@context": CONTEXT,
        }
        
        if district:
            entity["district"] = {"type": "Property", "value": district}
        
        # ‚úÖ NEW: Add polygon zone fields if present
        if zone_id:
            entity["zoneId"] = {"type": "Property", "value": zone_id}
        if zone_name:
            entity["zoneName"] = {"type": "Property", "value": zone_name}
        if trend:
            entity["waterTrend"] = {"type": "Property", "value": trend}
        
        # Add sensorInstanceId for deduplication (renamed from instanceId to avoid NGSI-LD reserved keyword conflict)
        entity["sensorInstanceId"] = {"type": "Property", "value": source_id}

        # ‚úÖ Send with retry
        res = send_to_orion(entity)

        logger.info(f"[FloodRiskSensor] Created {entity['id']} | Severity={severity} | WaterLevel={water_level}m")
        
        # Clear cache to get fresh data
        sensor_cache.clear()
        
        return {"status": "success", "entity_id": entity["id"], "severity": severity}

    except HTTPException:
        raise
    except requests.exceptions.RequestException as e:
        logger.error(f"Orion-LD communication error: {e}")
        raise HTTPException(502, "Cannot communicate with Orion-LD")
    except Exception as e:
        logger.error(f"Sensor processing error: {e}", exc_info=True)
        raise HTTPException(500, "Internal server error")

# ======================================================
# CROWD ROUTE ‚Üí FloodRiskCrowd - FIXED
# ======================================================

@app.post("/flood/crowd")
async def process_flood_crowd(request: Request):
    """Process crowd-sourced flood reports."""
    try:
        data = await request.json()
        logger.info("[CrowdReport] Processing")

        if "data" in data and isinstance(data["data"], list) and len(data["data"]) > 0:
            entity = data["data"][0]
        else:
            entity = data

        source_id = entity.get("id")
        
        # Extract address
        address = None
        if "address" in entity:
            if isinstance(entity["address"], dict) and "value" in entity["address"]:
                address = entity["address"]["value"]
            else:
                address = entity["address"]
        
        # Extract water level
        water_level_obj = entity.get("waterLevel", {})
        water_level = water_level_obj.get("value") if isinstance(water_level_obj, dict) else None
        
        # Extract other fields
        verified = entity.get("verified", {}).get("value", False) if isinstance(entity.get("verified"), dict) else entity.get("verified", False)
        description = entity.get("description", {}).get("value", "") if isinstance(entity.get("description"), dict) else entity.get("description", "")
        photos = entity.get("photos", {}).get("value", []) if isinstance(entity.get("photos"), dict) else entity.get("photos", [])
        timestamp = entity.get("timestamp", {}).get("value", now_iso()) if isinstance(entity.get("timestamp"), dict) else entity.get("timestamp", now_iso())

        # Validate location
        location_data = entity.get("location")
        if isinstance(location_data, dict) and "value" in location_data:
            location_data = location_data["value"]
            
        location = validate_location(location_data)
        
        if not location or not source_id or water_level is None:
            raise HTTPException(400, "Missing required fields: id, location, or waterLevel")

        # ‚úÖ FIXED: D√πng h√†m t√≠nh risk score m·ªõi
        risk_score, risk_level, factors = calculate_crowd_risk_score(
            water_level=water_level,
            description=description,
            photos=photos,
            verified=verified
        )

        crowd_confidence = "Verified" if verified else "Likely"

        entity_id = f"urn:ngsi-ld:FloodRiskCrowd:{uuid.uuid4()}"

        new_entity = {
            "id": entity_id,
            "type": "FloodRiskCrowd",
            "riskScore": {"type": "Property", "value": risk_score},
            "riskLevel": {"type": "Property", "value": risk_level},
            "waterLevel": {"type": "Property", "value": water_level, "unitCode": "MTR"},
            "crowdConfidence": {"type": "Property", "value": crowd_confidence},
            "factors": {"type": "Property", "value": factors},
            **({"address": {"type": "Property", "value": address}} if address else {}),
            "sourceReport": {"type": "Relationship", "object": source_id},
            "location": location,
            "calculatedAt": {"type": "Property", "value": now_iso()},
            "@context": CONTEXT
        }

        # ‚úÖ Send with retry
        res = send_to_orion(new_entity)

        logger.info(f"[FloodRiskCrowd] Created {entity_id} | Risk={risk_level} | Score={risk_score}")

        # Clear cache
        snapshot_cache.clear()

        return {
            "status": "success",
            "entity_id": entity_id,
            "risk_score": risk_score,
            "risk_level": risk_level,
            "factors": factors,
            "orion_status": res.status_code
        }

    except HTTPException:
        raise
    except requests.exceptions.RequestException as e:
        logger.error(f"Orion-LD error: {str(e)}")
        raise HTTPException(502, "Orion-LD communication error")
    except Exception as e:
        logger.error(f"Crowd processing error: {str(e)}", exc_info=True)
        raise HTTPException(500, "Internal server error")

# ======================================================
# FILE UPLOAD VALIDATION
# ======================================================

ALLOWED_EXTENSIONS = {'.jpg', '.jpeg', '.png', '.webp', '.gif'}
MAX_FILE_SIZE = 10 * 1024 * 1024  # 10MB

async def validate_image(file: UploadFile) -> bytes:
    """Validate uploaded image file."""
    # Check extension
    ext = os.path.splitext(file.filename or "")[1].lower()
    if ext not in ALLOWED_EXTENSIONS:
        raise HTTPException(400, f"Invalid file type: {ext}. Allowed: {', '.join(ALLOWED_EXTENSIONS)}")
    
    # Read and check size
    content = await file.read()
    if len(content) > MAX_FILE_SIZE:
        raise HTTPException(400, f"File too large. Max size: {MAX_FILE_SIZE // (1024*1024)}MB")
    
    # Verify it's actually an image
    try:
        img = Image.open(io.BytesIO(content))
        img.verify()
    except Exception:
        raise HTTPException(400, "Invalid or corrupted image file")
    
    # Reset file pointer
    await file.seek(0)
    return content

# ======================================================
# REPORT ROUTE - FIXED with validation
# ======================================================

@app.post("/report", response_model=CreateReportResult, tags=["Reports"], summary="G·ª≠i b√°o c√°o ng·∫≠p")
async def report(
    description: str = Form(..., description="M√¥ t·∫£ t√¨nh tr·∫°ng ng·∫≠p", example="Ng·∫≠p s√¢u 50cm, xe m√°y kh√¥ng qua ƒë∆∞·ª£c"),
    reporterId: str = Form(..., description="ID ng∆∞·ªùi b√°o c√°o", example="user_123"),
    latitude: Optional[float] = Form(None, description="Vƒ© ƒë·ªô", example=10.762622),
    longitude: Optional[float] = Form(None, description="Kinh ƒë·ªô", example=106.660172),
    water_level: Optional[float] = Form(None, description="M·ª©c n∆∞·ªõc (m√©t)", example=0.5),
    images: List[UploadFile] = File([], description="·∫¢nh minh h·ªça (t·ªëi ƒëa 10MB/·∫£nh)"),
):
    """
    üìù **G·ª≠i b√°o c√°o ng·∫≠p l·ª•t t·ª´ ng∆∞·ªùi d√¢n**
    
    API ƒë·ªÉ mobile app ho·∫∑c web g·ª≠i b√°o c√°o v·ªÅ t√¨nh tr·∫°ng ng·∫≠p.
    
    **Y√™u c·∫ßu**:
    - `description`: M√¥ t·∫£ chi ti·∫øt (b·∫Øt bu·ªôc)
    - `reporterId`: ID ƒë·ªãnh danh ng∆∞·ªùi b√°o (b·∫Øt bu·ªôc)
    
    **T√πy ch·ªçn**:
    - `latitude`, `longitude`: T·ªça ƒë·ªô GPS
    - `water_level`: ∆Ø·ªõc t√≠nh m·ª©c n∆∞·ªõc (m√©t)
    - `images`: Upload ·∫£nh minh h·ªça (JPEG, PNG, WebP)
    
    H·ªá th·ªëng s·∫Ω t·ª± ƒë·ªông t√≠nh **Risk Score** d·ª±a tr√™n m·ª©c n∆∞·ªõc v√† keywords trong m√¥ t·∫£.
    """
    try:
        # ‚úÖ Validate coordinates if provided
        if latitude is not None and longitude is not None:
            if not validate_coordinates(latitude, longitude):
                raise HTTPException(400, "Invalid coordinates for Vietnam")
        
        # ‚úÖ Validate water level
        if water_level is not None and (water_level < 0 or water_level > 20):
            raise HTTPException(400, "Water level must be between 0 and 20 meters")
        
        # ‚úÖ Validate images
        for img in images:
            await validate_image(img)
        
        # Save files
        image_urls = save_files_local(images, BASE_URL)
        
        entity_id = create_crowd_report_entity(
            description=description,
            reporterId=reporterId,
            photo_urls=image_urls,
            lat=latitude,
            lng=longitude,
            water_level=water_level
        )
        
        return {
            "id": entity_id,
            "status": "created",
            "image_urls": image_urls,
            "waterLevel": water_level
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Report submission error: {str(e)}", exc_info=True)
        raise HTTPException(500, "Failed to submit report")

# ===========================================================
# API CITIZEN REPORTS - B√ÅO C√ÅO NG∆Ø·ªúI D√ÇN
# ===========================================================

@app.get("/api/reports/recent", tags=["Reports"], summary="B√°o c√°o g·∫ßn ƒë√¢y")
async def get_recent_reports(
    limit: int = Query(20, description="S·ªë l∆∞·ª£ng b√°o c√°o t·ªëi ƒëa", ge=1, le=100),
    hours: int = Query(24, description="L·∫•y b√°o c√°o trong N gi·ªù g·∫ßn ƒë√¢y", ge=1, le=168)
):
    """
    üìù **L·∫•y danh s√°ch b√°o c√°o ng·∫≠p t·ª´ ng∆∞·ªùi d√¢n**
    
    Tr·∫£ v·ªÅ c√°c b√°o c√°o c·ªông ƒë·ªìng (citizen reports) trong kho·∫£ng th·ªùi gian g·∫ßn ƒë√¢y.
    
    Th√¥ng tin m·ªói b√°o c√°o:
    - V·ªã tr√≠ (lat/lng)
    - M·ª©c n∆∞·ªõc (m)
    - Risk score v√† Risk level
    - ƒê·ªãa ch·ªâ
    - Th·ªùi gian b√°o c√°o
    
    S·∫Øp x·∫øp theo th·ªùi gian (m·ªõi nh·∫•t tr∆∞·ªõc).
    """
    try:
        records = execute_query(f"""
            SELECT 
                entity_id,
                entity_type,
                longitude(location_centroid) AS lng,
                latitude(location_centroid) AS lat,
                riskscore,
                risklevel,
                waterlevel,
                address,
                calculatedat,
                crowdconfidence
            FROM doc.etfloodriskcrowd
            WHERE location_centroid IS NOT NULL
            AND calculatedat > NOW() - INTERVAL '{hours} hours'
            ORDER BY calculatedat DESC
            LIMIT {limit}
        """)
        
        # Format response
        reports = []
        for r in records:
            reports.append({
                "id": r.get("entity_id"),
                "lat": r.get("lat"),
                "lng": r.get("lng"),
                "waterLevel": r.get("waterlevel"),
                "riskScore": r.get("riskscore"),
                "riskLevel": r.get("risklevel"),
                "address": r.get("address"),
                "confidence": r.get("crowdconfidence", "Unknown"),
                "reportedAt": r.get("calculatedat"),
                "type": "community"
            })
        
        return {
            "reports": reports,
            "total": len(reports),
            "hours": hours,
            "timestamp": now_iso()
        }
    except Exception as e:
        logger.error(f"Get recent reports error: {str(e)}")
        raise HTTPException(500, "Failed to get recent reports")


@app.get("/api/reports/{report_id}")
async def get_report_detail(report_id: str):
    """
    ‚úÖ API: L·∫•y chi ti·∫øt m·ªôt b√°o c√°o c·ª• th·ªÉ.
    """
    try:
        records = execute_query("""
            SELECT 
                entity_id,
                entity_type,
                longitude(location_centroid) AS lng,
                latitude(location_centroid) AS lat,
                riskscore,
                risklevel,
                waterlevel,
                address,
                calculatedat,
                crowdconfidence,
                factors
            FROM doc.etfloodriskcrowd
            WHERE entity_id = ?
            LIMIT 1
        """, [report_id])
        
        if not records:
            raise HTTPException(404, "Report not found")
        
        r = records[0]
        return {
            "id": r.get("entity_id"),
            "lat": r.get("lat"),
            "lng": r.get("lng"),
            "waterLevel": r.get("waterlevel"),
            "riskScore": r.get("riskscore"),
            "riskLevel": r.get("risklevel"),
            "address": r.get("address"),
            "confidence": r.get("crowdconfidence"),
            "factors": r.get("factors"),
            "reportedAt": r.get("calculatedat"),
            "type": "community"
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Get report detail error: {str(e)}")
        raise HTTPException(500, "Failed to get report detail")


# ======================================================
# WEATHER API - OpenWeather Integration
# ======================================================

from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address
from slowapi.errors import RateLimitExceeded

from .services.weather_service import (
    get_weather_for_district,
    get_weather_all_districts,
    get_weather_with_forecast,
    get_weather_summary,
    get_all_districts,
    HCMC_DISTRICTS
)

# ======================================================
# RATE LIMITING - SECURITY
# ======================================================

limiter = Limiter(key_func=get_remote_address)
app.state.limiter = limiter
app.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)
from .services.gemini_service import (
    chat_with_weather_ai,
    get_weather_advice,
    analyze_flood_risk,
    clear_session,
    get_session_info
)
from .services.alert_enhancer import (
    enhance_alert_description,
    enhance_multiple_alerts
)

@app.get("/api/weather/districts")
async def get_districts_list():
    """Get list of all HCMC districts."""
    return {
        "districts": HCMC_DISTRICTS,
        "total": len(HCMC_DISTRICTS),
        "city": "TP. H·ªì Ch√≠ Minh"
    }

@app.get("/api/weather/current", tags=["Weather"], summary="Th·ªùi ti·∫øt hi·ªán t·∫°i")
async def get_current_weather(
    district_ids: Optional[str] = Query(None, description="Danh s√°ch qu·∫≠n (e.g., q1,q7,thu_duc)", example="q1,q7,binh_thanh")
):
    """
    üå§Ô∏è **L·∫•y th·ªùi ti·∫øt hi·ªán t·∫°i c√°c qu·∫≠n TP.HCM**
    
    D·ªØ li·ªáu t·ª´ **OpenWeather API** bao g·ªìm:
    - Nhi·ªát ƒë·ªô, ƒë·ªô ·∫©m
    - T√¨nh tr·∫°ng m√¢y, gi√≥
    - D·ª± b√°o m∆∞a 5 gi·ªù t·ªõi
    
    **District IDs c√≥ s·∫µn**: q1, q3, q4, q5, q6, q7, q8, q10, q11, q12, 
    binh_tan, binh_thanh, go_vap, phu_nhuan, tan_binh, tan_phu, 
    thu_duc, binh_chanh, can_gio, cu_chi, hoc_mon, nha_be
    
    N·∫øu kh√¥ng truy·ªÅn `district_ids`, tr·∫£ v·ªÅ 6 qu·∫≠n ch√≠nh.
    """
    try:
        ids = district_ids.split(",") if district_ids else None
        weather_data = await get_weather_with_forecast(ids)
        
        if not weather_data:
            raise HTTPException(503, "Kh√¥ng th·ªÉ l·∫•y d·ªØ li·ªáu th·ªùi ti·∫øt t·ª´ OpenWeather")
        
        return {
            "success": True,
            "data": weather_data,
            "total": len(weather_data),
            "timestamp": now_iso()
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Weather API error: {e}")
        raise HTTPException(500, f"L·ªói khi l·∫•y d·ªØ li·ªáu th·ªùi ti·∫øt: {str(e)}")

@app.get("/api/weather/all")
async def get_all_weather():
    """Get current weather for ALL HCMC districts (22 districts)."""
    try:
        weather_data = await get_weather_all_districts()
        
        if not weather_data:
            raise HTTPException(503, "Kh√¥ng th·ªÉ l·∫•y d·ªØ li·ªáu th·ªùi ti·∫øt")
        
        summary = get_weather_summary(weather_data)
        
        return {
            "success": True,
            "data": weather_data,
            "summary": summary,
            "total": len(weather_data),
            "timestamp": now_iso()
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Weather all API error: {e}")
        raise HTTPException(500, f"L·ªói: {str(e)}")

@app.get("/api/weather/{district_id}")
async def get_district_weather(district_id: str):
    """Get detailed weather for a specific district with 5-hour forecast."""
    try:
        weather_data = await get_weather_for_district(district_id)
        
        if not weather_data:
            raise HTTPException(404, f"Kh√¥ng t√¨m th·∫•y qu·∫≠n: {district_id}")
        
        return {
            "success": True,
            "data": weather_data,
            "timestamp": now_iso()
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"District weather API error: {e}")
        raise HTTPException(500, f"L·ªói: {str(e)}")

# ======================================================
# CHATBOT API - Gemini AI Integration
# ======================================================

from pydantic import BaseModel

class ChatRequest(BaseModel):
    message: str
    session_id: Optional[str] = "default"

class ChatResponse(BaseModel):
    success: bool
    response: str
    session_id: str
    timestamp: str
    error: Optional[str] = None

@app.post("/api/chat", response_model=ChatResponse, tags=["Chatbot"], summary="Chat v·ªõi AI Assistant")
@limiter.limit("30/minute")
async def chat_endpoint(request: Request, chat_request: ChatRequest):
    """
    ü§ñ **Chat v·ªõi tr·ª£ l√Ω AI FloodWatch**
    
    Chatbot t√≠ch h·ª£p **Google Gemini AI** c√≥ kh·∫£ nƒÉng:
    - Tr·∫£ l·ªùi c√¢u h·ªèi v·ªÅ th·ªùi ti·∫øt TP.HCM
    - C·∫£nh b√°o ng·∫≠p l·ª•t theo khu v·ª±c
    - ƒê∆∞a ra l·ªùi khuy√™n di chuy·ªÉn
    - Hi·ªÉu ng·ªØ c·∫£nh cu·ªôc tr√≤ chuy·ªán
    
    **Context t·ª± ƒë·ªông**: Bot t·ª± ƒë·ªông c√≥ th√¥ng tin th·ªùi ti·∫øt v√† ng·∫≠p l·ª•t hi·ªán t·∫°i.
    
    **Rate limit**: 30 requests/ph√∫t
    
    **V√≠ d·ª• c√¢u h·ªèi**:
    - "H√¥m nay Qu·∫≠n 7 c√≥ m∆∞a kh√¥ng?"
    - "T√¥i c√≥ n√™n ƒëi qua Nguy·ªÖn H·ªØu C·∫£nh kh√¥ng?"
    - "Qu·∫≠n n√†o ƒëang ng·∫≠p n·∫∑ng nh·∫•t?"
    """
    try:
        # L·∫•y d·ªØ li·ªáu th·ªùi ti·∫øt hi·ªán t·∫°i ƒë·ªÉ ƒë∆∞a v√†o context
        weather_data = await get_weather_with_forecast()
        
        # L·∫•y summary ng·∫≠p l·ª•t
        flood_data = None
        try:
            crowd = cached_get_snapshot_crowd(100)
            sensor = cached_get_snapshot_sensor(100)
            
            severe_count = len([r for r in crowd if r.get('risklevel') == 'Severe'])
            severe_count += len([r for r in sensor if r.get('severity') == 'Severe'])
            
            high_count = len([r for r in crowd if r.get('risklevel') == 'High'])
            high_count += len([r for r in sensor if r.get('severity') == 'High'])
            
            # L·∫•y summary t·ª´ weather
            summary = get_weather_summary(weather_data) if weather_data else {}
            
            flood_data = {
                "severe": severe_count,
                "high": high_count,
                "total": len(crowd) + len(sensor),
                "rainyDistricts": summary.get("rainyDistricts", []),
                "districtsWithRainForecast": summary.get("districtsWithRainForecast", [])
            }
        except Exception as e:
            logger.warning(f"Could not get flood data for chat context: {e}")
        
        # G·ªçi Gemini AI
        result = await chat_with_weather_ai(
            user_message=chat_request.message,
            session_id=chat_request.session_id,
            weather_data=weather_data,
            flood_data=flood_data
        )
        
        return ChatResponse(**result)
        
    except Exception as e:
        logger.error(f"Chat API error: {e}")
        return ChatResponse(
            success=False,
            response="Xin l·ªói, t√¥i g·∫∑p s·ª± c·ªë khi x·ª≠ l√Ω c√¢u h·ªèi. Vui l√≤ng th·ª≠ l·∫°i!",
            session_id=chat_request.session_id,
            timestamp=now_iso(),
            error=str(e)
        )

@app.post("/api/chat/clear")
async def clear_chat_session(session_id: str = "default"):
    """Clear chat history for a session."""
    clear_session(session_id)
    return {
        "success": True,
        "message": f"ƒê√£ x√≥a l·ªãch s·ª≠ chat cho session: {session_id}"
    }

@app.get("/api/chat/session/{session_id}")
async def get_chat_session(session_id: str):
    """Get info about a chat session."""
    return get_session_info(session_id)

@app.get("/api/weather/advice")
async def get_quick_advice():
    """Get quick weather advice based on current conditions."""
    try:
        weather_data = await get_weather_with_forecast()
        advice = await get_weather_advice(weather_data)
        
        return {
            "success": True,
            "advice": advice,
            "timestamp": now_iso()
        }
    except Exception as e:
        logger.error(f"Weather advice API error: {e}")
        raise HTTPException(500, f"L·ªói: {str(e)}")

@app.get("/api/flood/risk-analysis", tags=["Prediction"], summary="Ph√¢n t√≠ch r·ªßi ro ng·∫≠p")
async def get_flood_risk_analysis():
    """
    üîÆ **Ph√¢n t√≠ch r·ªßi ro ng·∫≠p b·∫±ng AI**
    
    S·ª≠ d·ª•ng Gemini AI ƒë·ªÉ ph√¢n t√≠ch:
    - T√¨nh tr·∫°ng ng·∫≠p hi·ªán t·∫°i
    - D·ª± b√°o th·ªùi ti·∫øt
    - ƒê∆∞a ra ƒë√°nh gi√° r·ªßi ro
    """
    try:
        weather_data = await get_weather_with_forecast()
        
        # Get flood data
        crowd = cached_get_snapshot_crowd(100)
        sensor = cached_get_snapshot_sensor(100)
        
        summary = get_weather_summary(weather_data) if weather_data else {}
        
        flood_data = {
            "severe": len([r for r in crowd if r.get('risklevel') == 'Severe']) + 
                     len([r for r in sensor if r.get('severity') == 'Severe']),
            "high": len([r for r in crowd if r.get('risklevel') == 'High']) + 
                   len([r for r in sensor if r.get('severity') == 'High']),
            "total": len(crowd) + len(sensor),
            "rainyDistricts": summary.get("rainyDistricts", []),
            "districtsWithRainForecast": summary.get("districtsWithRainForecast", [])
        }
        
        analysis = await analyze_flood_risk(weather_data, flood_data)
        
        return {
            "success": True,
            "analysis": analysis,
            "weatherSummary": summary,
            "floodData": flood_data,
            "timestamp": now_iso()
        }
    except Exception as e:
        logger.error(f"Flood risk analysis API error: {e}")
        raise HTTPException(500, f"L·ªói: {str(e)}")

# ======================================================
# ALERT ENHANCEMENT API - NEW
# ======================================================

@app.post("/api/alerts/enhance", tags=["Alerts"], summary="T·∫°o m√¥ t·∫£ c·∫£nh b√°o th√¥ng minh")
async def enhance_alert(
    water_level: float = Query(..., description="M·ª±c n∆∞·ªõc (m√©t)", ge=0, le=5),
    location: Optional[str] = Query(None, description="ƒê·ªãa ch·ªâ/v·ªã tr√≠"),
    district: Optional[str] = Query(None, description="Qu·∫≠n/huy·ªán"),
    severity: Optional[str] = Query(None, description="M·ª©c ƒë·ªô (Severe/High/Moderate/Low)"),
    trend: Optional[str] = Query(None, description="Xu h∆∞·ªõng (rising/stable/falling)")
):
    """
    ü§ñ **T·∫°o m√¥ t·∫£ c·∫£nh b√°o th√¥ng minh b·∫±ng Gemini AI**
    
    S·ª≠ d·ª•ng Gemini AI ƒë·ªÉ t·∫°o m√¥ t·∫£ c·∫£nh b√°o ƒë·ªông d·ª±a tr√™n:
    - M·ª±c n∆∞·ªõc th·ª±c t·∫ø
    - D·ªØ li·ªáu th·ªùi ti·∫øt
    - V·ªã tr√≠ v√† l·ªãch s·ª≠ ng·∫≠p
    
    **V√≠ d·ª•**:
    ```
    POST /api/alerts/enhance?water_level=1.2&district=Qu·∫≠n 12&severity=Severe
    ```
    """
    try:
        # L·∫•y d·ªØ li·ªáu th·ªùi ti·∫øt cho qu·∫≠n n√†y
        weather_data = None
        if district:
            try:
                weather_all = await get_weather_with_forecast()
                if weather_all:
                    weather_data = next(
                        (w for w in weather_all if w.get("location") == district or w.get("district") == district),
                        None
                    )
            except Exception as e:
                logger.warning(f"Could not fetch weather for district {district}: {e}")
        
        # L·∫•y d·ªØ li·ªáu ng·∫≠p xung quanh
        flood_data = None
        if location or district:
            try:
                # L·∫•y t·ªça ƒë·ªô t·ª´ location n·∫øu c√≥
                # T·∫°m th·ªùi b·ªè qua, c√≥ th·ªÉ th√™m reverse geocoding sau
                pass
            except Exception as e:
                logger.warning(f"Could not fetch flood data: {e}")
        
        # T·∫°o m√¥ t·∫£ th√¥ng minh
        enhanced_description = await enhance_alert_description(
            water_level=water_level,
            location=location,
            district=district,
            severity=severity,
            weather_data=weather_data,
            flood_data=flood_data,
            trend=trend
        )
        
        return {
            "success": True,
            "description": enhanced_description,
            "water_level": water_level,
            "location": location,
            "district": district,
            "severity": severity,
            "timestamp": now_iso()
        }
    except Exception as e:
        logger.error(f"Alert enhancement API error: {e}")
        raise HTTPException(500, f"L·ªói: {str(e)}")

@app.post("/api/alerts/enhance-batch", tags=["Alerts"], summary="T·∫°o m√¥ t·∫£ cho nhi·ªÅu c·∫£nh b√°o")
async def enhance_alerts_batch(request: Request):
    """
    ü§ñ **T·∫°o m√¥ t·∫£ cho nhi·ªÅu c·∫£nh b√°o c√πng l√∫c**
    
    Nh·∫≠n danh s√°ch c·∫£nh b√°o v√† tr·∫£ v·ªÅ danh s√°ch ƒë√£ ƒë∆∞·ª£c tƒÉng c∆∞·ªùng m√¥ t·∫£.
    """
    try:
        body = await request.json()
        alerts = body.get("alerts", [])
        
        if not alerts:
            raise HTTPException(400, "Danh s√°ch c·∫£nh b√°o kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng")
        
        # L·∫•y d·ªØ li·ªáu th·ªùi ti·∫øt
        weather_data = None
        try:
            weather_data = await get_weather_with_forecast()
        except Exception as e:
            logger.warning(f"Could not fetch weather data: {e}")
        
        # TƒÉng c∆∞·ªùng m√¥ t·∫£
        enhanced_alerts = await enhance_multiple_alerts(
            alerts=alerts,
            weather_data=weather_data
        )
        
        return {
            "success": True,
            "alerts": enhanced_alerts,
            "total": len(enhanced_alerts),
            "timestamp": now_iso()
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Batch alert enhancement API error: {e}")
        raise HTTPException(500, f"L·ªói: {str(e)}")


# ======================================================
# FLOOD PREDICTION API - NEW
# ======================================================

# Danh s√°ch c√°c zone d·ªÖ b·ªã ng·∫≠p (t·ª´ d·ªØ li·ªáu th·ª±c t·∫ø TP.HCM)
VULNERABLE_ZONES = [
    {"id": "nguyen_huu_canh", "name": "Nguy·ªÖn H·ªØu C·∫£nh", "district": "B√¨nh Th·∫°nh", "base_risk": 0.8},
    {"id": "pham_van_dong", "name": "Ph·∫°m VƒÉn ƒê·ªìng", "district": "B√¨nh Th·∫°nh", "base_risk": 0.7},
    {"id": "vo_van_ngan", "name": "V√µ VƒÉn Ng√¢n", "district": "Th·ªß ƒê·ª©c", "base_risk": 0.75},
    {"id": "huynh_tan_phat", "name": "Hu·ª≥nh T·∫•n Ph√°t", "district": "Qu·∫≠n 7", "base_risk": 0.7},
    {"id": "nguyen_van_linh", "name": "Nguy·ªÖn VƒÉn Linh", "district": "Qu·∫≠n 7", "base_risk": 0.65},
    {"id": "an_duong_vuong", "name": "An D∆∞∆°ng V∆∞∆°ng", "district": "Qu·∫≠n 6", "base_risk": 0.7},
    {"id": "nguyen_van_qua", "name": "Nguy·ªÖn VƒÉn Qu√°", "district": "Qu·∫≠n 12", "base_risk": 0.65},
    {"id": "truong_chinh", "name": "Tr∆∞·ªùng Chinh", "district": "T√¢n B√¨nh", "base_risk": 0.6},
]

def get_tidal_phase() -> float:
    """
    T√≠nh to√°n ·∫£nh h∆∞·ªüng tri·ªÅu c∆∞·ªùng.
    Tri·ªÅu c∆∞·ªùng TP.HCM th∆∞·ªùng cao v√†o th√°ng 9-12 (√¢m l·ªãch).
    """
    from datetime import datetime
    month = datetime.now().month
    
    # Tri·ªÅu c∆∞·ªùng m·∫°nh nh·∫•t: th√°ng 10-11
    if month in [10, 11]:
        return 0.9
    elif month in [9, 12]:
        return 0.7
    elif month in [8, 1]:
        return 0.5
    else:
        return 0.3

def calculate_rain_probability(weather_data: list) -> float:
    """T√≠nh x√°c su·∫•t m∆∞a t·ª´ d·ªØ li·ªáu th·ªùi ti·∫øt."""
    if not weather_data:
        return 0.3
    
    rain_count = 0
    total = len(weather_data)
    
    for district in weather_data:
        # Check current rain
        if district.get("isRaining"):
            rain_count += 1.5  # ƒêang m∆∞a = +1.5
        
        # Check forecast
        forecast = district.get("forecast", [])
        for f in forecast[:3]:  # X√©t 3 gi·ªù t·ªõi
            if f.get("pop", 0) > 0.5:  # Probability of precipitation > 50%
                rain_count += 0.3
    
    return min(rain_count / (total * 2), 1.0)

def generate_advisory(risk_score: float, high_risk_zones: list) -> dict:
    """T·∫°o l·ªùi khuy√™n d·ª±a tr√™n risk score."""
    if risk_score > 0.7:
        level = "üî¥ CAO"
        message = "Nguy c∆° ng·∫≠p cao trong 6 gi·ªù t·ªõi. H·∫°n ch·∫ø di chuy·ªÉn qua c√°c v√πng tr≈©ng."
        actions = [
            "Tr√°nh c√°c tuy·∫øn ƒë∆∞·ªùng hay ng·∫≠p",
            "Chu·∫©n b·ªã ph∆∞∆°ng √°n d·ª± ph√≤ng",
            "Theo d√µi c·∫≠p nh·∫≠t t·ª´ FloodWatch",
            "Di chuy·ªÉn xe √¥ t√¥ l√™n v·ªã tr√≠ cao"
        ]
    elif risk_score > 0.4:
        level = "üü° TRUNG B√åNH"
        message = "C√≥ kh·∫£ nƒÉng ng·∫≠p c·ª•c b·ªô. L∆∞u √Ω khi di chuy·ªÉn."
        actions = [
            "Ki·ªÉm tra t√¨nh tr·∫°ng ƒë∆∞·ªùng tr∆∞·ªõc khi ƒëi",
            "Mang theo √°o m∆∞a/d√π",
            "Tr√°nh ƒë·ªó xe ·ªü v√πng tr≈©ng"
        ]
    else:
        level = "üü¢ TH·∫§P"
        message = "Nguy c∆° ng·∫≠p th·∫•p. ƒêi·ªÅu ki·ªán di chuy·ªÉn t·ªët."
        actions = [
            "V·∫´n n√™n mang theo √°o m∆∞a",
            "Theo d√µi d·ª± b√°o th·ªùi ti·∫øt"
        ]
    
    return {
        "level": level,
        "message": message,
        "actions": actions,
        "high_risk_zones": [z["name"] for z in high_risk_zones[:5]]
    }

@app.get("/api/flood/prediction", tags=["Prediction"], summary="D·ª± ƒëo√°n ng·∫≠p 6 gi·ªù t·ªõi")
async def predict_flood():
    """
    üîÆ **D·ª± ƒëo√°n nguy c∆° ng·∫≠p trong 6 gi·ªù t·ªõi**
    
    Thu·∫≠t to√°n d·ª± ƒëo√°n d·ª±a tr√™n:
    - **Weather forecast** (60%): D·ª± b√°o m∆∞a t·ª´ OpenWeather
    - **Tidal effect** (40%): ·∫¢nh h∆∞·ªüng tri·ªÅu c∆∞·ªùng TP.HCM
    - **Historical data**: C√°c v√πng d·ªÖ b·ªã ng·∫≠p
    
    Tr·∫£ v·ªÅ:
    - Risk score (0-1)
    - C√°c zone c√≥ nguy c∆° cao
    - L·ªùi khuy√™n di chuy·ªÉn
    
    **L∆∞u √Ω**: ƒê√¢y l√† d·ª± ƒëo√°n d·ª±a tr√™n model ƒë∆°n gi·∫£n, 
    c·∫ßn k·∫øt h·ª£p v·ªõi th√¥ng tin th·ª±c t·∫ø ƒë·ªÉ ƒë∆∞a ra quy·∫øt ƒë·ªãnh.
    """
    try:
        # L·∫•y d·ªØ li·ªáu th·ªùi ti·∫øt
        weather_data = await get_weather_with_forecast()
        
        # T√≠nh c√°c y·∫øu t·ªë
        rain_probability = calculate_rain_probability(weather_data)
        tidal_effect = get_tidal_phase()
        
        # L·∫•y d·ªØ li·ªáu ng·∫≠p hi·ªán t·∫°i
        sensor_data = cached_get_snapshot_sensor(100)
        current_severe = len([r for r in sensor_data if r.get('severity') == 'Severe'])
        current_high = len([r for r in sensor_data if r.get('severity') == 'High'])
        
        # Current flood factor (0-1)
        current_flood_factor = min((current_severe * 0.3 + current_high * 0.15) / 5, 0.3)
        
        # Combined risk score
        # 50% weather + 30% tidal + 20% current conditions
        risk_score = round(
            0.50 * rain_probability + 
            0.30 * tidal_effect + 
            0.20 * current_flood_factor,
            3
        )
        
        # X√°c ƒë·ªãnh c√°c zone c√≥ nguy c∆° cao
        high_risk_zones = []
        for zone in VULNERABLE_ZONES:
            zone_risk = zone["base_risk"] * (0.5 + risk_score * 0.5)
            if zone_risk > 0.5:
                high_risk_zones.append({
                    **zone,
                    "predicted_risk": round(zone_risk, 2)
                })
        
        # S·∫Øp x·∫øp theo risk
        high_risk_zones.sort(key=lambda x: x["predicted_risk"], reverse=True)
        
        # T·∫°o advisory
        advisory = generate_advisory(risk_score, high_risk_zones)
        
        # L·∫•y weather summary
        weather_summary = get_weather_summary(weather_data) if weather_data else {}
        
        return {
            "success": True,
            "prediction": {
                "next_6h_risk": risk_score,
                "risk_level": advisory["level"],
                "high_risk_zones": high_risk_zones,
                "advisory": advisory,
                "factors": {
                    "rain_probability": round(rain_probability, 2),
                    "tidal_effect": round(tidal_effect, 2),
                    "current_flood_factor": round(current_flood_factor, 2)
                }
            },
            "weather": {
                "rainy_districts": weather_summary.get("rainyDistricts", []),
                "forecast_rain": weather_summary.get("districtsWithRainForecast", []),
                "avg_humidity": weather_summary.get("avgHumidity", 0)
            },
            "current_situation": {
                "severe_count": current_severe,
                "high_count": current_high,
                "total_alerts": len(sensor_data)
            },
            "timestamp": now_iso(),
            "disclaimer": "D·ª± ƒëo√°n mang t√≠nh tham kh·∫£o. Vui l√≤ng theo d√µi th√¥ng tin ch√≠nh th·ª©c."
        }
    except Exception as e:
        logger.error(f"Flood prediction error: {e}")
        raise HTTPException(500, f"L·ªói d·ª± ƒëo√°n ng·∫≠p: {str(e)}")

# ======================================================
# ROOT & HEALTH CHECK
# ======================================================

@app.get("/", tags=["Health"], summary="API Info")
def root():
    """üè† **Th√¥ng tin API FloodWatch**"""
    return {
        "message": "FloodWatch API Service",
        "version": "3.2.0",
        "status": "operational",
        "features": [
            "Improved severity calculation (absolute water level)",
            "Vietnamese keywords support",
            "Radius filter support",
            "TTL caching",
            "Connection pooling",
            "Retry mechanism",
            "Image validation",
            "Recent reports API",
            "OpenWeather Integration (HCMC 22 districts)",
            "Gemini AI Chatbot"
        ],
        "endpoints": {
            "health": "/health",
            "websocket": "/ws/map",
            "dashboard_stats": "/api/dashboard/stats",
            "districts": "/api/dashboard/districts",
            "nearby": "/api/flood/nearby",
            "report": "/report",
            "recent_reports": "/api/reports/recent",
            "report_detail": "/api/reports/{report_id}",
            "weather_current": "/api/weather/current",
            "weather_all": "/api/weather/all",
            "weather_district": "/api/weather/{district_id}",
            "weather_districts_list": "/api/weather/districts",
            "weather_advice": "/api/weather/advice",
            "chat": "/api/chat",
            "flood_risk_analysis": "/api/flood/risk-analysis"
        }
    }

@app.get("/health", tags=["Health"], summary="Health Check")
def health_check():
    """
    üíö **Ki·ªÉm tra tr·∫°ng th√°i h·ªá th·ªëng**
    
    Ki·ªÉm tra k·∫øt n·ªëi ƒë·∫øn:
    - Orion-LD Context Broker
    - CrateDB Time-series Database
    
    Tr·∫°ng th√°i:
    - `healthy`: T·∫•t c·∫£ services ho·∫°t ƒë·ªông
    - `degraded`: M·ªôt s·ªë services kh√¥ng kh·∫£ d·ª•ng
    - `unhealthy`: L·ªói nghi√™m tr·ªçng
    """
    try:
        # Test Orion connection
        orion_ok = False
        try:
            # Orion-LD 400 n·∫øu query qu√° r·ªông, n√™n d√πng /version ƒë·ªÉ ki·ªÉm tra up/down
            orion_health_url = ORION_LD_URL.split("/ngsi-ld")[0] + "/version"
            response = requests.get(orion_health_url, timeout=5)
            orion_ok = response.ok
        except Exception as e:
            logger.warning(f"Orion health check failed: {e}")
        
        # Test CrateDB connection
        cratedb_ok = False
        try:
            test_result = execute_query("SELECT 1 as test")
            cratedb_ok = len(test_result) > 0
        except:
            pass
        
        status = "healthy" if orion_ok and cratedb_ok else "degraded"
        
        return {
            "status": status,
            "orion_ld": "connected" if orion_ok else "disconnected",
            "cratedb": "connected" if cratedb_ok else "disconnected",
            "timestamp": now_iso(),
            "version": "3.0.0"
        }
    except Exception as e:
        logger.error(f"Health check failed: {str(e)}")
        return {
            "status": "unhealthy",
            "error": str(e),
            "timestamp": now_iso()
        }

# ======================================================
# STARTUP/SHUTDOWN EVENTS
# ======================================================

@app.on_event("startup")
async def startup_event():
    """Initialize application on startup."""
    logger.info("=" * 60)
    logger.info("FloodWatch Backend v3.0.0 Starting...")
    logger.info(f"Orion-LD: {ORION_LD_URL}")
    logger.info(f"CrateDB: {CRATEDB_HTTP_URL}")
    logger.info("Features: TTL Cache, Connection Pool, Retry, Radius Filter")
    logger.info("=" * 60)

@app.on_event("shutdown")
async def shutdown_event():
    """Cleanup on shutdown."""
    global _connection_pool
    if _connection_pool:
        try:
            _connection_pool.close()
        except:
            pass
    logger.info("FloodWatch Backend shutdown complete")
